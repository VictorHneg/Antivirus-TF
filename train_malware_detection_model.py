from sklearn.datasets import fetch_20newsgroups
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from sklearn.pipeline import Pipeline
import joblib
import pandas as pd
import time

# Constantes para hiperparâmetros
RANDOM_STATE = 42
NUM_ESTIMATORS = 100
TEST_SIZE = 0.2

def load_data():
    """Carrega o conjunto de dados."""
    return fetch_20newsgroups(subset='all', shuffle=True, random_state=RANDOM_STATE)

def train_model(data):
    """Treina e salva um modelo de classificação de floresta aleatória para detecção de malware."""
    try:
        # Dividir o conjunto de dados em treinamento e teste
        X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=TEST_SIZE, random_state=RANDOM_STATE)

        # Construir um pipeline com vetorização TF-IDF e classificador de floresta aleatória
        pipeline = Pipeline([
            ('tfidf', TfidfVectorizer()),
            ('clf', RandomForestClassifier(n_estimators=NUM_ESTIMATORS, random_state=RANDOM_STATE))
        ])

        # Definir os parâmetros para a busca em grade
        parameters = {
            'tfidf__max_df': (0.5, 0.75, 1.0),
            'tfidf__ngram_range': [(1, 1), (1, 2)],
            'clf__min_samples_split': [2, 5, 10]
        }

        # Realizar busca em grade para encontrar os melhores hiperparâmetros
        grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)
        grid_search.fit(X_train, y_train)

        # Avaliar o modelo
        y_pred = grid_search.predict(X_test)
        evaluate_model(y_test, y_pred)

        # Salvar o modelo treinado
        joblib.dump(grid_search.best_estimator_, 'malware_detection_model.joblib')
        
        return grid_search.best_estimator_
    except Exception as e:
        print(f"Erro durante o treinamento do modelo: {e}")

def evaluate_model(y_true, y_pred):
    """Avalia o modelo e salva métricas em um arquivo CSV."""
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')
    recall = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')
    
    report = classification_report(y_true, y_pred, output_dict=True)

    # Salvar métricas em um arquivo CSV
    metrics = {
        'Acurácia': accuracy,
        'Precisão': precision,
        'Recall': recall,
        'F1-score': f1,
        'Relatório de Classificação': report
    }
    df = pd.DataFrame.from_dict(metrics, orient='index')
    df.to_csv('metrics.csv', header=False)

def load_and_predict(input_texts):
    """Carrega o modelo treinado e faz previsões para uma lista de textos de entrada."""
    try:
        # Carregar o modelo treinado
        clf = joblib.load('malware_detection_model.joblib')

        # Fazer previsões
        predictions = clf.predict(input_texts)
        return predictions
    except Exception as e:
        print(f"Erro ao fazer previsões: {e}")
        return None

def main():
    """Função principal."""
    # Carregar os dados
    data = load_data()

    # Treinar o modelo
    model = train_model(data)

    # Fazer previsões em lote
    input_texts = ["Este é um texto suspeito de ser malware",
                   "Estou enviando um arquivo para análise"]
    predictions = load_and_predict(input_texts)

if __name__ == "__main__":
    main()